{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFI00gkzffHU8spR2v/I7e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Darshan0805/Natural-Language-Processing/blob/main/Sai_Darshan_548_Lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#a.Find the 3rd meaning of the word in the list."
      ],
      "metadata": {
        "id": "eqGNoRhda65r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSz8_9CvZ6G1",
        "outputId": "d56507eb-eceb-4dcb-ed38-56a0722bade3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: happy\n",
            "3rd Meaning: happy\n",
            "\n",
            "Word 'beautiful' has less than 3 meanings in WordNet.\n",
            "\n",
            "Word: strong\n",
            "3rd Meaning: potent\n",
            "\n",
            "Word: interesting\n",
            "3rd Meaning: interest\n",
            "\n",
            "Word: exciting\n",
            "3rd Meaning: excite\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import wordnet\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def get_synonyms(word):\n",
        "    synonyms = []\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            synonyms.append(lemma.name())\n",
        "    return synonyms\n",
        "\n",
        "# Example words\n",
        "words = [\"happy\", \"beautiful\", \"strong\", \"interesting\", \"exciting\"]\n",
        "\n",
        "for word in words:\n",
        "    synonyms = get_synonyms(word)\n",
        "    if len(synonyms) >= 3:\n",
        "        print(f\"Word: {word}\")\n",
        "        print(f\"3rd Meaning: {synonyms[2]}\\n\")\n",
        "    else:\n",
        "        print(f\"Word '{word}' has less than 3 meanings in WordNet.\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#b.Extract the nouns of the word from the synonyms list."
      ],
      "metadata": {
        "id": "2RFTLcLoazVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_nouns(word):\n",
        "    nouns = []\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            if lemma.name() != word and '_' not in lemma.name():\n",
        "                nouns.append(lemma.name())\n",
        "    return nouns\n",
        "\n",
        "words = ['run', 'walk', 'jump', 'swim', 'crawl']\n",
        "\n",
        "for word in words:\n",
        "    synonyms = get_nouns(word)\n",
        "    print(f\"Word: {word}\")\n",
        "    print(f\"Nouns: {synonyms}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ny4qiqmLatds",
        "outputId": "84a514b8-0a23-4b7c-bdd8-319b060484a5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: run\n",
            "Nouns: ['tally', 'test', 'trial', 'footrace', 'streak', 'running', 'running', 'rivulet', 'rill', 'runnel', 'streamlet', 'campaign', 'ladder', 'ravel', 'discharge', 'outpouring', 'scat', 'scarper', 'lam', 'bunk', 'escape', 'go', 'pass', 'lead', 'extend', 'operate', 'go', 'flow', 'feed', 'course', 'function', 'work', 'operate', 'go', 'range', 'campaign', 'play', 'tend', 'lean', 'incline', 'prevail', 'persist', 'endure', 'execute', 'carry', 'guide', 'draw', 'pass', 'lead', 'bleed', 'consort', 'ply', 'hunt', 'race', 'move', 'go', 'melt', 'ladder', 'unravel']\n",
            "\n",
            "Word: walk\n",
            "Nouns: ['walking', 'pass', 'walkway', 'paseo']\n",
            "\n",
            "Word: jump\n",
            "Nouns: ['leap', 'leap', 'saltation', 'startle', 'start', 'parachuting', 'jumping', 'leap', 'bound', 'spring', 'startle', 'start', 'rise', 'leap', 'derail', 'chute', 'parachute', 'leap', 'jumpstart', 'jump-start', 'skip', 'leap', 'alternate']\n",
            "\n",
            "Word: swim\n",
            "Nouns: ['swimming', 'float', 'drown']\n",
            "\n",
            "Word: crawl\n",
            "Nouns: ['crawling', 'creep', 'creeping', 'creep', 'fawn', 'creep', 'cringe', 'cower', 'grovel']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#c.Extract the verbs of the word from the synonyms list."
      ],
      "metadata": {
        "id": "xCmW5RPqeF6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_verbs(word):\n",
        "    verbs = []\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            if lemma.name() != word and '_' not in lemma.name() and syn.pos() == 'v':\n",
        "                verbs.append(lemma.name())\n",
        "    return verbs\n",
        "\n",
        "words = ['happy', 'sad', 'excited', 'angry', 'calm']\n",
        "\n",
        "for word in words:\n",
        "    verbs = get_verbs(word)\n",
        "    print(f\"Word: {word}\")\n",
        "    print(f\"Verbs: {verbs}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sv6jnxXNbO3m",
        "outputId": "51fc62d4-8be9-4505-fa6a-6fac954ac6d1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: happy\n",
            "Verbs: []\n",
            "\n",
            "Word: sad\n",
            "Verbs: []\n",
            "\n",
            "Word: excited\n",
            "Verbs: ['excite', 'stimulate', 'excite', 'stimulate', 'excite', 'stir', 'agitate', 'rouse', 'charge', 'commove', 'excite', 'arouse', 'sex', 'excite', 'stimulate', 'shake', 'excite', 'stir', 'excite', 'energize', 'energise', 'excite']\n",
            "\n",
            "Word: angry\n",
            "Verbs: []\n",
            "\n",
            "Word: calm\n",
            "Verbs: ['quiet', 'tranquilize', 'tranquillize', 'tranquillise', 'quieten', 'lull', 'still', 'steady', 'becalm', 'sedate', 'tranquilize', 'tranquillize', 'tranquillise']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#d.Extract the adjectives of the word from the synonyms list."
      ],
      "metadata": {
        "id": "HP43fKRPeL85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_adjectives(word):\n",
        "    adjectives = []\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            if lemma.name() != word and '_' not in lemma.name() and syn.pos() == 'a':\n",
        "                adjectives.append(lemma.name())\n",
        "    return adjectives\n",
        "\n",
        "words = ['big', 'sad', 'ugly', 'small', 'gentle']\n",
        "\n",
        "for word in words:\n",
        "    adjectives = get_adjectives(word)\n",
        "    print(f\"Word: {word}\")\n",
        "    print(f\"Adjectives: {adjectives}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlFq8BnNbpbJ",
        "outputId": "973f9b1d-cd32-458f-af4a-f8a54ee5e9f5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: big\n",
            "Adjectives: ['large']\n",
            "\n",
            "Word: sad\n",
            "Adjectives: []\n",
            "\n",
            "Word: ugly\n",
            "Adjectives: []\n",
            "\n",
            "Word: small\n",
            "Adjectives: ['little']\n",
            "\n",
            "Word: gentle\n",
            "Adjectives: []\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#e.Extract the adverbs of the word from the synonyms list."
      ],
      "metadata": {
        "id": "YtX-VOVaeRYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_adverbs(word):\n",
        "    adverbs = []\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            if lemma.name() != word and '_' not in lemma.name() and syn.pos() == 'r':\n",
        "                adverbs.append(lemma.name())\n",
        "    return adverbs\n",
        "\n",
        "\n",
        "words = ['quickly', 'slowly', 'rapidly', 'hastily', 'carefully']\n",
        "\n",
        "for word in words:\n",
        "    adverbs = get_adverbs(word)\n",
        "    print(f\"Word: {word}\")\n",
        "    print(f\"Adverbs: {adverbs}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcD9O1becC0K",
        "outputId": "99e2269b-3627-4be0-90f1-a9f5f5d7460e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: quickly\n",
            "Adverbs: ['rapidly', 'speedily', 'chop-chop', 'apace', 'promptly', 'quick', 'cursorily']\n",
            "\n",
            "Word: slowly\n",
            "Adverbs: ['slow', 'easy', 'tardily', 'lento']\n",
            "\n",
            "Word: rapidly\n",
            "Adverbs: ['quickly', 'speedily', 'chop-chop', 'apace']\n",
            "\n",
            "Word: hastily\n",
            "Adverbs: ['hurriedly']\n",
            "\n",
            "Word: carefully\n",
            "Adverbs: ['cautiously']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#f.Extract the definition of the word."
      ],
      "metadata": {
        "id": "7NCrUPDNecF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "\n",
        "def get_definition(word):\n",
        "    synsets = wordnet.synsets(word)\n",
        "    if synsets:\n",
        "        return synsets[0].definition()\n",
        "    else:\n",
        "        return f\"No definition found for '{word}'\"\n",
        "\n",
        "words = ['computer', 'telephone', 'carpet', 'guitar', 'rainbow']\n",
        "\n",
        "for word in words:\n",
        "    definition = get_definition(word)\n",
        "    print(f\"Word: {word}\")\n",
        "    print(f\"Definition: {definition}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZd9yJbicEGQ",
        "outputId": "ccb93a48-f926-4be8-b5a1-4a4029abff1d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: computer\n",
            "Definition: a machine for performing calculations automatically\n",
            "\n",
            "Word: telephone\n",
            "Definition: electronic equipment that converts sound into electrical signals that can be transmitted over distances and then converts received signals back into sounds\n",
            "\n",
            "Word: carpet\n",
            "Definition: floor covering consisting of a piece of thick heavy fabric (usually with nap or pile)\n",
            "\n",
            "Word: guitar\n",
            "Definition: a stringed instrument usually having six strings; played by strumming or plucking\n",
            "\n",
            "Word: rainbow\n",
            "Definition: an arc of colored light in the sky caused by refraction of the sun's rays by rain\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#g.Find the hypernyms of each word."
      ],
      "metadata": {
        "id": "L9mkNFUTeheD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hypernyms(word):\n",
        "    hypernyms = []\n",
        "    synsets = wordnet.synsets(word)\n",
        "    if synsets:\n",
        "        for synset in synsets:\n",
        "            for hypernym in synset.hypernyms():\n",
        "                hypernyms.extend(hypernym.lemma_names())\n",
        "    return list(set(hypernyms))  # Remove duplicates\n",
        "\n",
        "words = ['table', 'tree', 'bicycle', 'keyboard', 'elephant']\n",
        "\n",
        "for word in words:\n",
        "    hypernyms = get_hypernyms(word)\n",
        "    print(f\"Word: {word}\")\n",
        "    print(f\"Hypernyms: {hypernyms}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj5u3C4adE8Z",
        "outputId": "4c5544fb-2bfa-45b5-f2b8-bde4518cf899"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: table\n",
            "Hypernyms: ['assemblage', 'set', 'delay', 'plateau', 'article_of_furniture', 'gathering', 'fare', 'arrange', 'array', 'furniture', 'piece_of_furniture', 'tableland']\n",
            "\n",
            "Word: tree\n",
            "Hypernyms: ['channelise', 'trail', 'plane_figure', 'woody_plant', 'tail', 'give_chase', 'maneuver', 'ligneous_plant', 'chase_after', 'two-dimensional_figure', 'manoeuvre', 'steer', 'head', 'manoeuver', 'point', 'go_after', 'chase', 'dog', 'track', 'plant', 'elongate', 'set', 'direct', 'guide', 'channelize', 'stretch', 'tag']\n",
            "\n",
            "Word: bicycle\n",
            "Hypernyms: ['ride', 'wheeled_vehicle']\n",
            "\n",
            "Word: keyboard\n",
            "Hypernyms: ['device', 'holder']\n",
            "\n",
            "Word: elephant\n",
            "Hypernyms: ['pachyderm', 'emblem', 'allegory', 'proboscidean', 'proboscidian']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#h.Find the hyponyms of each word."
      ],
      "metadata": {
        "id": "MY7W0w_oemF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hyponyms(word):\n",
        "    hyponyms = []\n",
        "    synsets = wordnet.synsets(word)\n",
        "    if synsets:\n",
        "        for synset in synsets:\n",
        "            for hyponym in synset.hyponyms():\n",
        "                hyponyms.extend(hyponym.lemma_names())\n",
        "    return list(set(hyponyms))\n",
        "\n",
        "words = ['chair', 'apple', 'dog', 'shirt', 'river']\n",
        "\n",
        "for word in words:\n",
        "    hyponyms = get_hyponyms(word)\n",
        "    print(f\"Word: {word}\")\n",
        "    print(f\"Hyponyms: {hyponyms}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_uUVubgdT5W",
        "outputId": "262bc3dc-2878-47fa-c6f8-e0eee27ed6a5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: chair\n",
            "Hyponyms: ['highchair', 'chair_of_state', 'rocker', 'tablet-armed_chair', 'ladder-back_chair', 'chaise', 'fighting_chair', 'Eames_chair', 'lawn_chair', 'side_chair', 'Kalon_Tripa', 'barber_chair', 'armchair', 'ladder-back', 'rocking_chair', 'folding_chair', 'vice_chairman', 'garden_chair', 'daybed', 'straight_chair', 'swivel_chair', 'feeding_chair', 'chaise_longue', 'wheelchair']\n",
            "\n",
            "Word: apple\n",
            "Hyponyms: ['cooking_apple', 'crab_apple', 'crabapple', 'dessert_apple', 'eating_apple']\n",
            "\n",
            "Word: dog\n",
            "Hyponyms: ['puppy', 'working_dog', 'Newfoundland_dog', 'pug-dog', 'barker', 'Welsh_corgi', 'coach_dog', 'poodle', 'Great_Pyrenees', 'perisher', 'pooch', 'mutt', 'spitz', 'Newfoundland', 'poodle_dog', 'trace', 'mongrel', 'toy', 'corgi', 'hunting_dog', 'pug', 'doggy', 'Vienna_sausage', 'basenji', 'run_down', 'Leonberg', 'Mexican_hairless', 'bow-wow', 'lapdog', 'tree', 'griffon', 'hunt', 'Brussels_griffon', 'cur', 'dalmatian', 'toy_dog', 'hound', 'carriage_dog', 'Belgian_griffon', 'quest', 'doggie']\n",
            "\n",
            "Word: shirt\n",
            "Hyponyms: ['polo_shirt', 'sport_shirt', 'camise', 'dashiki', 'tee_shirt', 'dress_shirt', 'daishiki', 'jersey', 'hair_shirt', 'evening_shirt', 'tank_top', 'kurta', 'T-shirt', 'work-shirt']\n",
            "\n",
            "Word: river\n",
            "Hyponyms: []\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#i.Find the similarities of any two hyponyms of a word."
      ],
      "metadata": {
        "id": "p4HZbCHLeq49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hyponyms(word):\n",
        "    hyponyms = []\n",
        "    synsets = wordnet.synsets(word)\n",
        "    if synsets:\n",
        "        for synset in synsets:\n",
        "            for hyponym in synset.hyponyms():\n",
        "                hyponyms.append(hyponym)\n",
        "    return hyponyms\n",
        "\n",
        "word = 'animal'\n",
        "hyponyms = get_hyponyms(word)\n",
        "\n",
        "if len(hyponyms) >= 2:\n",
        "    # Calculate and print the similarity between the first two hyponyms\n",
        "    similarity = hyponyms[0].wup_similarity(hyponyms[1])\n",
        "    print(f\"Similarity between '{hyponyms[0].name()}' and '{hyponyms[1].name()}': {similarity}\")\n",
        "else:\n",
        "    print(f\"Word '{word}' has less than 2 hyponyms.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17xeFiRcd6eQ",
        "outputId": "15cc892b-6049-42bd-edb3-3c37f88c1b41"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between 'acrodont.n.01' and 'adult.n.02': 0.875\n"
          ]
        }
      ]
    }
  ]
}